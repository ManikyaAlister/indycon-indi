---
title: "Individual Level Analyses"
author: Anonymised
format: 
  pdf: 
    execute:
      echo: false
      warning: false
  # html:
  #   code-fold: true
  #   code-summary: "Show the code"
editor: visual
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include = FALSE


library(here)
library(tidyverse)
library(ggpubr)
library(RColorBrewer)
```

```{r}
load(here("analyses/derived-data/model_comparison.Rdata"))
load(here("data/clean/all_data_clean.Rdata"))
data <- all_data[[1]]
```

# Raw Data

```{r}
deltasPlot = function(remove_condition, title, xlab){
  
d_consensus <- data %>% 
  filter(consensus != remove_condition) 

comparisons <- unique(d_consensus$consensus)

  deltas_consensus <- d_consensus %>%
  pivot_wider(names_from = consensus, values_from = update) %>%
  group_by(participant) %>%
  summarise(delta = mean(independent, na.rm = TRUE)-mean(get(comparisons[comparisons != "independent"]), na.rm = TRUE))

means_consensus <- data %>%
    filter(consensus != remove_condition) %>%
  group_by(participant, consensus) %>%
  summarise(update = mean(update))
  

# Assuming deltas_independence and d_independence are your data frames

# Get the participant index ordered by delta
delta_order <- order(deltas_consensus$delta)
ordered_participants <- deltas_consensus$participant[delta_order]

# Make participant a factor which corresponds to the delta order
d_comparison <- data %>%
  filter(consensus != remove_condition) %>%
  mutate(
    participant = factor(participant, levels = ordered_participants)
  ) %>%
  arrange(participant)

# Create the plot
deltas_consensus %>%
  ggplot(aes(x = factor(participant, levels = ordered_participants), y = delta)) +
    geom_col(fill = "grey40", colour = "grey")+
  geom_point(data = means_consensus, aes(y = update, fill = consensus), alpha = .8, pch = 21) +
  scale_fill_viridis_d()+
  theme_bw()+
      theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          legend.position = "bottom"
          # axis.title=element_text(size=10),
          # plot.title = element_text(size = 12)
          #plot.margin = unit(c(1, 1, 1, 1), "cm")  # Increase top and bottom margins

          ) +
  labs(title = title,
       x = xlab,
       y = str_wrap("Belief difference (points = raw belief)"))

}

```

```{r}

title = "Independent Consensus vs. No Consensus (Independent Contested)"
xlab = "Participant (ordered by independent - contested)"

deltas_consensus <- deltasPlot(remove_condition = "dependent", title, xlab)
deltas_consensus
```

```{r}

title = "Independent Consensus vs. No Dependent Consensus"
xlab = "Participant (ordered by independent - dependent)"

deltas_ind <- deltasPlot(remove_condition = "contested", title, xlab)
deltas_ind
```

```{r}
combined_deltas <- ggarrange(deltas_consensus, deltas_ind, nrow = 2)
ggsave(filename = here("analyses/07_Plots/combined-deltas.png"), width = 10, height = 6, plot = combined_deltas)

```

# Modelling

```{r}
paramPlot = function(remove_condition, title, xlab, ylab){
  # re order subjects based on their consensus estimate
tmp <- model_comparison %>%
  filter(excluded_condition == remove_condition) 

ordered_subjects <- reorder(as.character(tmp$subject), tmp$consensus_estimate)

model_comparison_consensus <- model_comparison %>%
  filter(excluded_condition == remove_condition)  %>%
  rename("Best Model" = best_model)

  param_plot <- model_comparison_consensus %>%
    ggplot(aes(x = ordered_subjects, y = consensus_estimate)) +
        geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI, colour = `Best Model`), width = 0.2) +
    geom_point(aes(shape = `Best Model`, fill = `Best Model`), size = 2, stroke = .5) +  # Removed fill, using shape only
    labs(title = title,
         x = xlab,
         y = ylab) +
    geom_hline(yintercept = 0, colour = "black") +
    theme_bw() +
    scale_shape_manual(values = c(24, 21)) + 
    scale_fill_manual(values = c("darkgreen", "skyblue"))+
    scale_colour_manual(values = c("darkgreen", "skyblue"))+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          legend.position = "bottom")
#ggsave(plot = ind_param_plot, filename = "07_Plots/indv-param-independence.png", width = 10, height = 5)

param_plot
}
```

## How many people were sensitive to consensus

```{r}

title = "Independent Consensus vs. No Consensus (Independent Contested)"
xlab = "Participant (Ordered by consensus parameter, higher = more belief in consensus)"
ylab = "Consensus Parameter"
cons_param_plot <- paramPlot(remove_condition = "dependent", title, xlab, ylab)
cons_param_plot
```

```{r}
title = "Independent Consensus vs. Dependent Consensus"
xlab = "Participant (Ordered by independence parameter, > 0 = more belief in independence, < 0 = more belief in dependence)"
ylab = "Independence Parameter"
ind_param_plot <- paramPlot(remove_condition = "contested", title, xlab, ylab)
ind_param_plot
```

## How many have a preference for independent sources versus dependent sources, and how many aren't sensitive at all?

```{r}
combined_param_plots <- ggarrange(cons_param_plot, ind_param_plot, common.legend = TRUE, ncol = 1, nrow = 2)
ggsave(plot = combined_param_plots, filename = here("analyses/07_Plots/combined-param-plot.png"), width = 10, height = 4)
```

```{r}
model_comparison_ind <- model_comparison %>%
  filter(excluded_condition == "contested")  

n_independent <- sum(model_comparison_ind$best_model == "Alternative Model" & model_comparison_ind$consensus_estimate > 0)
n_dependent <- sum(model_comparison_ind$best_model == "Alternative Model" & model_comparison_ind$consensus_estimate < 0)

prop_alt <- round(sum(model_comparison_ind$best_model == "Alternative Model")/nrow(model_comparison_ind),2)*100

paste0("total proportion of participants best fit by the alernative model: ", prop_alt)

prop_independent <- round((n_independent/nrow(model_comparison_ind)),2)*100
prop_dependent <- round((n_dependent/nrow(model_comparison_ind)),2)*100

paste0("proportion of participants who preferred an independent consensus: ", prop_independent)
paste0("proportion of participants who preferred an dependent consensus: ", prop_dependent) 


estimates_ind <- model_comparison_ind[model_comparison_ind[,"best_model"] == "Alternative Model" & model_comparison_ind[,"consensus_estimate"] > 0, "consensus_estimate"]

paste0("Median estimate for participants who preferred an independent consensus: ", median(as.vector(as.matrix(estimates_ind))))

estimates_dep <-model_comparison_ind[model_comparison_ind[,"best_model"] == "Alternative Model" & model_comparison_ind[,"consensus_estimate"] < 0, "consensus_estimate"]
 
paste0("Median estimate for participants who preferred an dependent consensus: ",median(as.vector(as.matrix(estimates_dep))))

```

```{r}
#| include: false
# just checking to see whether the orders match across comparisons
# re order subjects based on their consensus estimate
# tmp <- model_comparison %>%
#   filter(excluded_condition == "contested") 
# 
# ordered_subjects_facet <- rep(ordered_subjects, each = 2)
# 
# model_comparison %>%
#   mutate(excluded_condition = case_when(
#       excluded_condition == "dependent" ~ "Contested v Independent",
#     excluded_condition == "contested" ~ "Independent v Dependent"
#   )) %>%
#   ggplot(aes(x = ordered_subjects_facet, y = consensus_estimate, colour = best_model)) +
#   geom_point(aes(shape = best_model)) +
#   geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI), width = 0.2) +
#   facet_grid(~excluded_condition)+
#   labs(title = "Individual Sensitivity to Consensus Effects",
#        x = "Participant (Ordered by independence parameter, higher = more belief in indeoendence)",
#        y = "Independence Parameter") +
#   geom_hline(yintercept = 0, colour = "black")+
#   theme_bw() +
#     theme(axis.text.x = element_blank(),
#           axis.ticks.x = element_blank(),
#           legend.position = "bottom") 
```

`r prop_alt`% of participants were sensitive to independence when reasoning. `r prop_dependent`% of participants were more convinced by a dependent consensus where four different people each shared the same source. `r prop_independent` % of participants were more convinced by an independent consensus where four people shared four different sources.

# Correlation between sessions for independence comparison

It is useful to know whether people who were labeled as preferring an independent v dependent consensus appeared to show consistent behavior across sessions.

```{r}
# deltas_ind_by_session <- data %>% 
#   filter(consensus != "contested") %>%
#   pivot_wider(names_from = consensus, values_from = update) %>%
#   group_by(participant, session_number) %>%
#   summarise(delta = median(independent, na.rm = TRUE)-median(dependent, na.rm = TRUE)) %>%
#   pivot_wider(names_from = session_number, values_from = delta) 
# 
# model_comparison_ind$delta_s1 <- deltas_ind_by_session$`1`
# model_comparison_ind$delta_s2 <- deltas_ind_by_session$`2`
# 
# alt_subs <- model_comparison_ind %>%
#   filter(best_model == "Alternative Model")
# 
# plot(alt_subs$delta_s1, alt_subs$delta_s2)
# cor(alt_subs$delta_s1, alt_subs$delta_s2)

```

```{r}
# deltas_ind_by_session <- data %>% 
#   filter(consensus != "contested") %>%
#   pivot_wider(names_from = consensus, values_from = update) %>%
#   group_by(participant, session_number) %>%
#   summarise(delta = median(independent, na.rm = TRUE)-median(dependent, na.rm = TRUE)) %>%
#   pivot_wider(names_from = session_number, values_from = delta) 
# 
# alt_subs <- model_comparison_ind %>%
#   filter(best_model == "Alternative Model")
# 
# plot(alt_subs$delta_s1, alt_subs$delta_s2)
# cor(alt_subs$delta_s1, alt_subs$delta_s2)
```

cor_all

```{r}
load(here("analyses/derived-data/model_comparison_by_session.Rdata"))

alt_participants <- as.vector(as.matrix(model_comparison_ind[model_comparison_ind[,"best_model"] == "Alternative Model","subject"]))

session_estimates <- model_comparison_by_session %>%
  pivot_wider(names_from = session_number,values_from = c(looic_null,looic_alt, consensus_estimate, lower_CI, upper_CI, best_model, looic_diff)) %>%
  select(subject, consensus_estimate_1, consensus_estimate_2) 

session_estimates$best_model_overall <- model_comparison_ind$best_model

# Assuming your data frame is named session_estimates
session_estimates %>%
  ggplot(aes(x = consensus_estimate_1, y = consensus_estimate_2, color = best_model_overall)) +
  geom_smooth(method = "lm", se = FALSE) + 
  geom_point() +
  #xlim(-20,30)+
  labs(title = "Consistency of conseneus independence score from session 1 and 2",
       x = "Consensus Estimate 1",
       y = "Consensus Estimate 2",
       color = "Best Model Overall")

cor_all <- cor.test(session_estimates$consensus_estimate_1, session_estimates$consensus_estimate_2)

session_estimates_alt <- filter(session_estimates, best_model_overall == "Alternative Model")

cor_alt <- cor.test(session_estimates_alt$consensus_estimate_1, session_estimates_alt$consensus_estimate_2)
cor_all
cor_alt

```

The correlation appears to suggest reasonably consistent individual differences. Among participants who were labelled as not being best fit by the null model, there was a strong correlation between session 1 and session 2 (0.56). We would not expect there to be any correlation for participants best fit by the null model, which there did not appear to be, as evidence by the very small, non-significant correlation (0.19) when including all participants and the blue line in the plot above.

It may also be interesting to know what the correlation looks like when we include participants who were labelled as being best fit by the alternative model in either session 1 or session 2, as well as overall.

```{r}
# find participants who were best fit by the alternative model in at least one session
at_least_one_session <- model_comparison_by_session %>% 
  mutate(best_model_code = case_when(
    best_model == "Null Model" ~ 0,
    best_model == "Alternative Model"~ 1
  )) %>%
  group_by(subject) %>%
  # see which participant was best fit by the alternative model in any session
  summarise(was_alt = max(best_model_code)) %>%
  # only inclulde participants who were best fit by the model in at least one session
  filter(was_alt == 1) %>%
  select(subject) %>%
  as.vector()


session_estimates_at_least_one <- session_estimates %>%
  filter(subject %in% at_least_one_session[[1]] | best_model_overall == "Alternative Model")

plot(session_estimates_at_least_one$consensus_estimate_1, session_estimates_at_least_one$consensus_estimate_2, xlab = "Session 1", ylab = "Session 2")

cor(session_estimates_at_least_one$consensus_estimate_1, session_estimates_at_least_one$consensus_estimate_2)

```

The correlation is much smaller, but this is not particularly informative as to the overall quality of our analysis/consistency of the results. If participants were labelled as being best described by the alternative model in only 1 session but not overall, this actually means that our analysis is doing a good job only classifying people who are consistently showing a particular behavior across the two sessions. It does tell us that having half the number of trials makes the analysis misleading because it can identify people as being best fit by the alternative model even when their results aren't consistent across sessions, which further justifies our sample size, but I do not think the low correlation suggests are results are inconsistent from session 1 to session 2.

# What strategy did people *say* they used?

Comparing their behavior with their self-reported preference.

```{r}

self_report <- as.data.frame(all_data$follow_up)

# get just the multiple choice anser
self_report_mc <- self_report$self_report_strategy
#self_report$subject <- 1:length(self_report[,1])
self_report$coefficient <- model_comparison_ind$consensus_estimate

self_report %>%
  group_by(self_report_strategy) %>%
  summarise(count = n(), mean_estimate = mean(coefficient))

mc_tally <- table(self_report_mc)
names(mc_tally) <- c("Consensus Only", "Independent", "None of Above", "No Strategy", "Dependent")

mc_tally_df <- as.data.frame(cbind(names(mc_tally), mc_tally)) 
colnames(mc_tally_df) <- c("Response", "Count")
mc_tally_df$Response <- factor(mc_tally_df$Response, levels = c("Independent", "Dependent", "Consensus Only", "No Strategy", "None of Above")) 

insight_barplot <- mc_tally_df %>%
  mutate(Count = as.numeric(Count)) %>%
  ggplot(aes(x = Response, y = Count, fill = Response)) +
  geom_col(color = "black", size = .5) +
  theme_bw() +
  scale_fill_viridis_d()+
  theme(legend.position = "none")  
  #scale_fill_brewer(palette = "Greens")

insight_barplot
```

Most people said they they were more convinced by diverse sources, even though that's not what their behavior showed.

Could it be that our model comparison is just penalizing too harshly? A lot of people show positive independence estimate in the first figure, even though the for most of them the model comparison preferred the null and the credible intervals were overlapping with zero.

## Proportion of people who said they preferred diverse sources in the full sample, versus those who had a positive beta indicating a (not necessarily credible) behavioral preference for diversity.

```{r}

# calculate the proportion of self reported "diverse" participants in the full sample 
prop_diverse_full <- sum(mc_tally["Independent"])/sum(mc_tally)

# find participants who at least had a positive consensus parameter estimate
pos_consensus <- model_comparison %>%
  filter(consensus_estimate > 0 & excluded_condition == "contested") %>%
  mutate(reported_strategy = self_report[self_report$participant == subject,"self_report_strategy"])

# calculate the proportion of self reported "diverse" participants with a positive beta
prop_diverse_pos <- sum(pos_consensus$reported_strategy == "diverse", na.rm = TRUE)/length(pos_consensus$reported_strategy)

# compare both proportions
prop_diverse_comparison <- c(`Full Sample` = prop_diverse_full, `Positive Beta` = prop_diverse_pos)

barplot(prop_diverse_comparison)
```

The above plot shows that the proportion of participants who said they preferred an indepen- dent consensus was only slightly higher for participants who showed behavior in line with that preference (positive beta) than in the full sample. This suggests that a lot of participants who said they preferred an independent consensus did not show behavior in line with this stated preference.

```{r}
self_report <- self_report %>%
  mutate(report_independence = ifelse(self_report_strategy == "diverse", T, F))
  
self_report %>%
  group_by(report_independence) %>%
  summarise(mean_coefficient =mean(coefficient)) %>%
  ggplot()+
  geom_col(aes(x = report_independence, y = mean_coefficient))

t.test(data = self_report, coefficient ~ report_independence)

mean(self_report$coefficient[self_report$report_independence == T])
```

## Matching self reported preference with

```{r}
model_comparison_ind$self_report <- self_report$self_report_strategy

model_comparison_ind <- model_comparison_ind %>% 
  filter(!is.na(self_report)) %>%
  mutate(`Self Reported Strategy` = case_when(
    self_report == "diverse" ~ "Independent",
    self_report == "repeated" ~ "Dependent",
    self_report == "consensusOnly" ~ "Consensus Only",
    self_report == "noStrategy" ~ "No Strategy",
    self_report == "none" ~ "None of Above"
  ))

# need to re-do the subject order with the NA participant removed
ordered_subjects <- reorder(as.character(model_comparison_ind$subject), model_comparison_ind$consensus_estimate)

  
ind_param_plot_self_report <- model_comparison_ind %>%
  #adjust order of report options in legend
  mutate(`Self Reported Strategy` = factor(`Self Reported Strategy`, levels = c("Independent", "Dependent", "Consensus Only", "No Strategy", "None of Above"))) %>%
  ggplot(aes(x = ordered_subjects, y = consensus_estimate, colour = `Self Reported Strategy`)) +
  geom_point(aes(), size =3) +
  geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI), width = 0.2) +
  labs(title = "Independent Consensus v Dependent Consensus (Coloured by Self Reported Strategy)",
       x = "Participant (Ordered by independence parameter, > 0 = more belief in independence, < 0 = more belief in dependence)",
       y = "Independence Parameter") +
  scale_colour_viridis_d()+
  geom_hline(yintercept = 0, colour = "black")+
  theme_bw() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          legend.position = "none") 


combined_insight_plots <- ggarrange( insight_barplot, ind_param_plot_self_report,common.legend = FALSE, ncol = 1, nrow = 2)
ggsave(plot = combined_insight_plots, filename = here("analyses/07_Plots/combined-insight-plot.png"), width = 10, height = 6)
combined_insight_plots

```

# Participants who weren't sensitive to consensus

```{r}

no_consensus_subs <- model_comparison %>%
  filter(best_model == "Null Model" & excluded_condition == "dependent") %>%
  select(subject) %>%
  as.matrix() %>%
  as.vector()

model_comparison %>%
  filter(subject %in% no_consensus_subs)
```

All of the participants who were insensitive to independence, except one, were sensitive to the standard consensus effect.

Two out of the three participants who did not show any standard consensus effect were sensitive to independence, such that they were more convinced by *dependent* (repeated) sources. This makes sense since these participants were relatively less persuaded by an independent consensus, which is what the contested (no consensus) condition was compared with to assess the standard consensus effect. It is probable that if we had assessed consensus by comparing the dependent consensus with the contested condition, these participants would have shown a consensus effect. It is interesting however, that for these participants, their preference for repeated, dependent sources appeared not just when compared to an independent consensus, but also when compared to no consensus at all.
